#!/usr/bin/env python3
import os

from dateutil import parser as date_parser
import math

import time
from datetime import datetime, timedelta, timezone
from functools import partial
from threading import Timer

import requests
import yaml
from requests.adapters import HTTPAdapter
from urllib3 import Retry

from measure import Measure

DESC = 'NewRelic measure driver for Optune'
HAS_CANCEL = True
VERSION = '0.1.1'

DFLT_WARMUP = 0
DFLT_DURATION = 120
DFLT_DELAY = 0

NEWRELIC_ACCOUNT_ID = str(open('/run/secrets/optune_newrelic_account_id').read()).strip()
NEWRELIC_APM_API_KEY = str(open('/run/secrets/optune_newrelic_apm_api_key').read()).strip()
NEWRELIC_APM_APP_ID = str(open('/run/secrets/optune_newrelic_apm_app_id').read()).strip()
NEWRELIC_INSIGHTS_QUERY_KEY = str(open('/run/secrets/optune_newrelic_insights_query_key').read()).strip()
APM_API_URL = 'https://api.newrelic.com/v2'
APM_INSTANCE_LIST_URL = '/applications/{app_id}/instances.json'
APM_INSTANCE_METRICS_URL = '/applications/{app_id}/instances/{instance_id}/metrics/data.json'
INSIGHTS_API_URL = 'https://insights-api.newrelic.com/v1/accounts/{account_id}/query'

# create a safe and desirable subset of the built-ins
_safe_builtins = {x: eval(x) for x in "False None True abs all any bool complex divmod enumerate filter float "
                                      "hash int iter len list map max min next pow range reversed round "
                                      "set slice sorted str sum tuple zip".split()}

# add a full set of usable math functions and constants
_safe_builtins.update(((x, getattr(math, x)) for x in dir(math) if not x.startswith('_')))

# add an empty "__builtins__" value, so that Python doesn't add one by itself
# see https://docs.python.org/3/library/functions.html#eval
_safe_builtins["__builtins__"] = {}


def safe_eval(inline_code, local_variables):
    return eval(inline_code, _safe_builtins, local_variables)


with open('./config.yaml') as f:
    config = yaml.load(f.read())['newrelic']


def url_session(prefix=None):
    if prefix is None:
        prefix = ""
    else:
        prefix = prefix.rstrip('/') + '/'

    def new_request(_prefix, f, method, url, *args, **kwargs):
        return f(method, _prefix + url, *args, **kwargs)

    s = requests.Session()
    s.request = partial(new_request, prefix, s.request)

    # Retries mechanism configuration
    retries = Retry(total=10, connect=5,
                    status=5,
                    method_whitelist=('GET',),
                    status_forcelist=(307, 408, 409, 429, 500, 502, 503, 504),
                    backoff_factor=.2)
    s.mount('http://', HTTPAdapter(max_retries=retries))
    s.mount('https://', HTTPAdapter(max_retries=retries))

    return s


apm_session = url_session(APM_API_URL)
apm_session.headers.update({'X-Api-Key': NEWRELIC_APM_API_KEY})

insights_session = url_session(INSIGHTS_API_URL.format(account_id=NEWRELIC_ACCOUNT_ID))
insights_session.headers.update({'X-Query-Key': NEWRELIC_INSIGHTS_QUERY_KEY})


class InsightsColumn:

    def __init__(self, contents, metadata):
        self.contents = contents
        self.metadata = metadata

    def is_named(self, name):
        if self.metadata['alias'] == name:
            return True
        return False

    def get_value(self):
        if 'members' in self.contents:
            return self.contents['members']
        else:
            for key, v in self.contents.items():
                if key.lower() == self.metadata['contents']['function']:
                    return v
        return None


class InsightsFacetedColumn:

    def __init__(self, facets, metadata, idx):
        self.idx = idx
        self.facets = facets
        self.metadata = metadata

    def is_named(self, name):
        if self.metadata['alias'] == name:
            return True
        return False

    def get_value(self):
        results = []
        for facet in self.facets:
            _data = []
            res = {'id': str(facet['name']), 'data': _data}
            for ts in facet['timeSeries']:
                value = ts['results'][self.idx][self.metadata['contents']['function']]
                _data.append([ts['beginTimeSeconds'], value])
            results.append(res)
        return results


class InsightsException(BaseException):
    pass


class InsightsQuery(dict):

    def __init__(self, data):
        dict.__init__(self, data=data)
        self.columns = []
        md_contents = data['metadata']['contents']

        if isinstance(md_contents, list):
            for i, metadata in enumerate(md_contents):
                column = InsightsColumn(data['results'][i], metadata)
                self.columns.append(column)

        if isinstance(md_contents, dict):
            if 'timeSeries' in md_contents:
                for i, col_md in enumerate(md_contents['timeSeries']['contents']):
                    if 'facets' in data:
                        column = InsightsFacetedColumn(data['facets'], col_md, idx=i)
                    else:
                        column = InsightsColumn(data, col_md)
                    self.columns.append(column)

    def get_column_by_name(self, column_name):
        for column in self.columns:
            if column.is_named(column_name):
                return column
        return None

    def get_column_value(self, column):
        column = self.get_column_by_name(column)
        if column:
            return column.get_value()
        return None


class APMInstances(dict):

    def __init__(self):
        dict.__init__(self, data=[])

    def add_response_data(self, instances_response_data):
        self['data'].append(instances_response_data)

    @property
    def instances(self):
        for instance in self['data']:
            yield from instance['application_instances']

    @property
    def ids(self):
        return list(map(lambda inst: inst['id'], self.instances))


class APMMetrics(dict):

    def __init__(self):
        dict.__init__(self, data=[])

    def add_response_data(self, metrics_response_data):
        self['data'].append(metrics_response_data)

    def get_metric(self, name):
        return APMMetric(name, data=self['data'])


class APMMetric:

    def __init__(self, metric_name, data):
        self.metric_name = metric_name
        self.data = data

    def __getattr__(self, item):
        instances = self.data
        ret = []
        for instance in instances:
            _id = instance['instance_id']
            r = {'id': str(_id), 'data': []}
            data = r['data']
            m = None
            for metric in instance['metric_data']['metrics']:
                if metric['name'] == self.metric_name:
                    m = metric
                    break
            for ts in m['timeslices']:
                value = ts['values'][item]
                timestamp = int(date_parser.parse(ts['from']).timestamp())
                data.append([timestamp, value])
            ret.append(r)
        return ret


class NewRelicDriver(Measure):
    progress_timer = None
    time_to_wait = 0
    time_left = 0

    def stop_timer(self):
        if self.progress_timer:
            self.progress_timer.cancel()

    def start_timer(self):
        self.stop_timer()
        self.time_left -= 1
        self.progress_timer = Timer(1, self.update_progress)
        self.progress_timer.start()

    def update_progress(self):
        self.progress = int((1 - self.time_left / self.time_to_wait) * 80)
        self.start_timer()

    def measure(self):
        skip_sleep = os.environ.get('SKIP_SLEEP', False)
        self.progress_message = 'Measurements started'
        self.print_progress()

        control = self.input_data.get('control', {})
        warmup = int(control.get('warmup', DFLT_WARMUP))
        duration = int(control.get('duration', DFLT_DURATION))
        delay = int(control.get('delay', DFLT_DELAY))

        self.time_to_wait = warmup + duration + delay
        self.time_left = self.time_to_wait
        self.start_timer()

        # Warmup nap
        if warmup > 0:
            self.progress = 0
            self.progress_message = 'WARMUP: sleeping {} seconds'.format(warmup)
            if not skip_sleep:
                time.sleep(warmup)

        # Wait before gathering measurements (historical data)
        self.progress_message = 'DURATION: waiting {} seconds for measurements'.format(duration)
        if not skip_sleep:
            time.sleep(duration)

        metrics = {}
        measure_to = datetime.now(timezone.utc).replace(microsecond=0)
        measure_from = measure_to - timedelta(seconds=duration)

        # Delay measurements
        self.progress_message = 'DELAY: sleeping {} seconds'.format(delay)
        if not skip_sleep:
            time.sleep(delay)
        self.stop_timer()

        config_fetches = config['fetch']
        config_fetches_len = len(config_fetches)
        config_metrics = config['metrics']

        fetches = {}
        for i, fetch in enumerate(config_fetches):
            fetch_name = fetch['name']
            fetch_api = fetch['api']
            self.progress = 80 + ((i / config_fetches_len) * 20)
            self.progress_message = 'Fetching data for {}'.format(fetch_name)

            # Handle Insights API call.
            if fetch_api == 'insights':
                query = fetch['query'].format(from_time=measure_from.isoformat(),
                                              to_time=measure_to.isoformat())
                response = insights_session.get('', params=dict(nrql=query))
                data = response.json()
                if 'error' in data:
                    raise InsightsException('{}\nIn Query:\n{}'.format(data['error'], query))
                fetches[fetch_name] = InsightsQuery(data)

            # Handle APM Instance List API call.
            if fetch_api == 'apm_instances_list':
                hostnames = safe_eval(fetch['hostnames'],
                                      local_variables=fetches)
                hosts = APMInstances()
                for hostname in hostnames:
                    response = apm_session.get(APM_INSTANCE_LIST_URL.format(app_id=NEWRELIC_APM_APP_ID),
                                               params={'filter[hostname]': hostname})
                    hosts.add_response_data(response.json())
                fetches[fetch_name] = hosts

            # Handle APM Metrics Data API call.
            if fetch_api == 'apm_metrics_data':
                fetch_metrics = fetch['metrics']

                def get_metric_values(_metrics):
                    for m in _metrics:
                        yield from m['values']

                fetches[fetch_name] = a = APMMetrics()
                apm_instance_ids = safe_eval(fetch['instance_ids'], local_variables=fetches)
                for apm_instance_id in apm_instance_ids:
                    response = apm_session.get(APM_INSTANCE_METRICS_URL.format(
                        app_id=NEWRELIC_APM_APP_ID,
                        instance_id=apm_instance_id,
                    ), params={
                        'names[]': list(map(lambda m: m['name'], fetch_metrics)),
                        'values[]': list(get_metric_values(fetch_metrics)),
                        'from': measure_from.isoformat(),
                        'to': measure_to.isoformat(),
                        'period': 60,
                        'summarize': False,
                        'raw': True,
                    })
                    a.add_response_data({'instance_id': apm_instance_id, **response.json()})

        for config_metric in config_metrics:
            name = config_metric['name']
            excluded = ['name']
            compiled_metric = {**dict(filter(lambda m: m[0] not in excluded, config_metric.items()))}
            if 'values' in config_metric:
                val = safe_eval(config_metric['values'], fetches)
                assert isinstance(val, list), \
                    'List of per-instance timeseries was expected in a config file formula ' \
                    'under key "values" for metric "{}". Got value of type "{}" instead.'.format(name, type(val))
                compiled_metric['values'] = val
            elif 'value' in config_metric:
                val = safe_eval(config_metric['value'], fetches)
                assert isinstance(val, (int, float, str, bool)), \
                    'Scalar value was expected in a config file formula ' \
                    'under key "value" for metric "{}". Got value of type "{}" instead.'.format(name, type(val))
                compiled_metric['value'] = val
            metrics[name] = compiled_metric

        self.progress = 100
        self.progress_message = 'Measurements completed'
        self.print_progress()

        return metrics, {}

    def describe(self):
        metrics = {}
        for metric in config['metrics']:
            keys = {}
            for mk, mv in metric.items():
                if mk not in ['name', 'value', 'values']:
                    keys[mk] = mv
            metrics[metric['name']] = keys
        return metrics

    def handle_cancel(self, **kwargs):
        print('Cancelling measurements')
        quit(0)


if __name__ == '__main__':
    driver = NewRelicDriver(cli_desc=DESC, supports_cancel=HAS_CANCEL, version=VERSION)
    driver.run()
